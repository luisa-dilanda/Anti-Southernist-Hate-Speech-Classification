{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0c26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7424933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ddef8bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\dilan\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\dilan\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ec215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_duplicates(df):\n",
    "    df = df.drop_duplicates(subset='text', keep=\"first\") #rimuovi i testi duplicati\n",
    "    df = df[df['text'].notna()] #remove NaNs\n",
    "    df = df.reset_index(drop=True) #reset index\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b1d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_char_df(df, char, subst_char, column_name='text'):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    for i in range(len(df)):\n",
    "        text=str(df[column_name][i])\n",
    "        text=text.replace(char, subst_char)\n",
    "        df[column_name][i]=text\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d911b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(texts, lemmatizer, stopwords):\n",
    "    prepr_texts=[]\n",
    "    for i in range(len(texts)):\n",
    "        review = re.sub('[^a-zA-Z]', ' ', texts[i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "        review = ' '.join(review)\n",
    "        prepr_texts.append(review)\n",
    "    return prepr_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bbf6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "traintest = pd.read_pickle('C:/Users/dilan/Downloads/5. Analisi Statistica dei Dati/0. Tesi/final_aug.pkl') \n",
    "validation = pd.read_pickle('C:/Users/dilan/Downloads/5. Analisi Statistica dei Dati/0. Tesi/final_validation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee228f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dilan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>textlen</th>\n",
       "      <th>translated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.liberoquotidiano.it/news/politica/...</td>\n",
       "      <td>05 maggio 2024 a\\n\\na\\n\\na\\n\\nForza Italia cre...</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>May 5, 2024 a\\n\\na\\n\\na\\n\\nForza Italia is gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.liberoquotidiano.it/news/italia/39...</td>\n",
       "      <td>05 maggio 2024 a\\n\\na\\n\\na\\n\\nTragedia in Valt...</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>May 5, 2024 a\\n\\na\\n\\na\\n\\nTragedy in Valtelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.liberoquotidiano.it/news/sport/392...</td>\n",
       "      <td>05 maggio 2024 a\\n\\na\\n\\na\\n\\nScarico, demotiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>353</td>\n",
       "      <td>May 5, 2024 a\\n\\na\\n\\na\\n\\nExhausted, demotiva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.liberoquotidiano.it/news/sport/392...</td>\n",
       "      <td>05 maggio 2024 a\\n\\na\\n\\na\\n\\nDomenica importa...</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>May 5, 2024 a\\n\\na\\n\\na\\n\\nAn important Sunday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://salerno.corriere.it/notizie/cronaca/24...</td>\n",
       "      <td>di Luigi Martino\\n\\nSolo sei iscritti tra i 3 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>by Luigi Martino\\n\\nOnly six children between ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.liberoquotidiano.it/news/politica/...   \n",
       "1  https://www.liberoquotidiano.it/news/italia/39...   \n",
       "2  https://www.liberoquotidiano.it/news/sport/392...   \n",
       "3  https://www.liberoquotidiano.it/news/sport/392...   \n",
       "4  https://salerno.corriere.it/notizie/cronaca/24...   \n",
       "\n",
       "                                                text label  textlen  \\\n",
       "0  05 maggio 2024 a\\n\\na\\n\\na\\n\\nForza Italia cre...     0      263   \n",
       "1  05 maggio 2024 a\\n\\na\\n\\na\\n\\nTragedia in Valt...     0      190   \n",
       "2  05 maggio 2024 a\\n\\na\\n\\na\\n\\nScarico, demotiv...     0      353   \n",
       "3  05 maggio 2024 a\\n\\na\\n\\na\\n\\nDomenica importa...     0      283   \n",
       "4  di Luigi Martino\\n\\nSolo sei iscritti tra i 3 ...     0      327   \n",
       "\n",
       "                                     translated_text  \n",
       "0  May 5, 2024 a\\n\\na\\n\\na\\n\\nForza Italia is gro...  \n",
       "1  May 5, 2024 a\\n\\na\\n\\na\\n\\nTragedy in Valtelli...  \n",
       "2  May 5, 2024 a\\n\\na\\n\\na\\n\\nExhausted, demotiva...  \n",
       "3  May 5, 2024 a\\n\\na\\n\\na\\n\\nAn important Sunday...  \n",
       "4  by Luigi Martino\\n\\nOnly six children between ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopword removal and lemmatization/stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "en_stopwords = nltk.corpus.stopwords.words('english')\n",
    "it_stopwords = nltk.corpus.stopwords.words('italian')\n",
    "\n",
    "en_lemmatizer = WordNetLemmatizer()\n",
    "it_stemmer = SnowballStemmer('italian')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "traintest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cdce159",
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest=replace_char_df(traintest, '[', '')\n",
    "traintest=replace_char_df(traintest, '[', '', column_name='translated_text')\n",
    "validation=replace_char_df(validation, '[', '')\n",
    "validation=replace_char_df(validation, '[', '', column_name='translated_text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956dea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest['tag']='tt'\n",
    "validation['tag']='val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9913cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([traintest, validation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ca96448",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=df['translated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062c1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f070364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=df['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f431965",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr_texts=preproc(texts, en_lemmatizer, en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb9d8164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722\n",
      "1408\n"
     ]
    }
   ],
   "source": [
    "# TOGLIERE DOPPIONI\n",
    "millesimodataframe = {'text': prepr_texts, 'label': y, 'tag':tags\n",
    "                     }\n",
    "\n",
    "millesimodataframe = pd.DataFrame(millesimodataframe)\n",
    "print(len(millesimodataframe))\n",
    "\n",
    "\n",
    "nd_f_ing=remove_text_duplicates(millesimodataframe)\n",
    "print(len(nd_f_ing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352ba09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11d4c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 1408, n_features: 16534\n"
     ]
    }
   ],
   "source": [
    "nd_f_ing_x=nd_f_ing['text']\n",
    "\n",
    "# tf idf INGLESE\n",
    "tf_idf = TfidfVectorizer()\n",
    "#applying tf idf to training data\n",
    "tfidf = tf_idf.fit_transform(nd_f_ing_x)\n",
    "#applying tf idf to training data\n",
    "tfidf_ttval = tf_idf.transform(nd_f_ing_x)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % tfidf_ttval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0aae311c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    806\n",
       "1    602\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_f_ing['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a19120de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_y=nd_f_ing['label']\n",
    "nd_tags=nd_f_ing['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "711d1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n"
     ]
    }
   ],
   "source": [
    "#CREA DF DI NUOVO\n",
    "tfidf_df = {'text':nd_f_ing_x, 'tfidf': tfidf_ttval, 'label': nd_y, 'tag':nd_tags\n",
    "                     }\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_df)\n",
    "print(len(tfidf_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "49fdfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIVIDI IN DUE DF\n",
    "grouped=tfidf_df.groupby(tfidf_df.tag)\n",
    "traintest=grouped.get_group(\"tt\")\n",
    "validation=grouped.get_group(\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e6627f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>label</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>may forza italia growing poll proving sexy ant...</td>\n",
       "      <td>(0, 16425)\\t0.03502392823437498\\n  (0, 16397...</td>\n",
       "      <td>0</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may tragedy valtellina woman fell zipline died...</td>\n",
       "      <td>(0, 16521)\\t0.29042628127321013\\n  (0, 16460...</td>\n",
       "      <td>0</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>may exhausted demotivated stunned crazy rumor ...</td>\n",
       "      <td>(0, 16425)\\t0.02707553427061538\\n  (0, 16347...</td>\n",
       "      <td>0</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>may important sunday term salvation draw lecce...</td>\n",
       "      <td>(0, 16462)\\t0.08809776813024404\\n  (0, 16347...</td>\n",
       "      <td>0</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luigi martino six child year old registered mu...</td>\n",
       "      <td>(0, 16460)\\t0.09065708976460579\\n  (0, 16446...</td>\n",
       "      <td>0</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>fifth paragraph constitution prescribes state ...</td>\n",
       "      <td>(0, 16466)\\t0.04476784189339855\\n  (0, 16440...</td>\n",
       "      <td>1</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>fifth paragraph constitution prescribes state ...</td>\n",
       "      <td>(0, 16466)\\t0.04453005132174843\\n  (0, 16440...</td>\n",
       "      <td>1</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>fifth paragraph constitution prescribes state ...</td>\n",
       "      <td>(0, 16466)\\t0.04476784189339855\\n  (0, 16440...</td>\n",
       "      <td>1</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>th paragraph constitution prescribes state exa...</td>\n",
       "      <td>(0, 16466)\\t0.044750987365828644\\n  (0, 1644...</td>\n",
       "      <td>1</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>fifth paragraph constitution prescribes state ...</td>\n",
       "      <td>(0, 16466)\\t0.04476784189339855\\n  (0, 16440...</td>\n",
       "      <td>1</td>\n",
       "      <td>tt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    may forza italia growing poll proving sexy ant...   \n",
       "1    may tragedy valtellina woman fell zipline died...   \n",
       "2    may exhausted demotivated stunned crazy rumor ...   \n",
       "3    may important sunday term salvation draw lecce...   \n",
       "4    luigi martino six child year old registered mu...   \n",
       "..                                                 ...   \n",
       "872  fifth paragraph constitution prescribes state ...   \n",
       "873  fifth paragraph constitution prescribes state ...   \n",
       "874  fifth paragraph constitution prescribes state ...   \n",
       "875  th paragraph constitution prescribes state exa...   \n",
       "876  fifth paragraph constitution prescribes state ...   \n",
       "\n",
       "                                                 tfidf label tag  \n",
       "0      (0, 16425)\\t0.03502392823437498\\n  (0, 16397...     0  tt  \n",
       "1      (0, 16521)\\t0.29042628127321013\\n  (0, 16460...     0  tt  \n",
       "2      (0, 16425)\\t0.02707553427061538\\n  (0, 16347...     0  tt  \n",
       "3      (0, 16462)\\t0.08809776813024404\\n  (0, 16347...     0  tt  \n",
       "4      (0, 16460)\\t0.09065708976460579\\n  (0, 16446...     0  tt  \n",
       "..                                                 ...   ...  ..  \n",
       "872    (0, 16466)\\t0.04476784189339855\\n  (0, 16440...     1  tt  \n",
       "873    (0, 16466)\\t0.04453005132174843\\n  (0, 16440...     1  tt  \n",
       "874    (0, 16466)\\t0.04476784189339855\\n  (0, 16440...     1  tt  \n",
       "875    (0, 16466)\\t0.044750987365828644\\n  (0, 1644...     1  tt  \n",
       "876    (0, 16466)\\t0.04476784189339855\\n  (0, 16440...     1  tt  \n",
       "\n",
       "[877 rows x 4 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64590b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttx=traintest['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ea79027",
   "metadata": {},
   "outputs": [],
   "source": [
    "tty=traintest['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bcb9a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ratio = 0.80\n",
    "test_ratio = 0.20\n",
    "feature, feature_test, labels, labels_test = train_test_split(ttx, tty, test_size=1 - train_ratio)\n",
    "\n",
    "# feature=feature.reset_index(drop=True)\n",
    "\n",
    "# feature_test=feature_test.reset_index(drop=True)\n",
    "\n",
    "# labels=labels.reset_index(drop=True)\n",
    "\n",
    "# labels_test=labels_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "239e3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d730d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation score\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB()\n",
    "]\n",
    "\n",
    "cross_value_scored = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "   \n",
    "    # Convert feature to a dense NumPy array if it's sparse\n",
    "    if sp.issparse(feature):\n",
    "        feature_dense = feature.toarray()\n",
    "    else:\n",
    "        feature_dense = feature  # If not sparse, use feature directly\n",
    "\n",
    "    # Check if feature_dense is an object array and contains sparse matrices\n",
    "    if feature_dense.dtype == 'object' and any(sp.issparse(element) for element in feature_dense):\n",
    "        feature_dense = np.vstack([element.toarray() for element in feature_dense]) # stack the elements of arrays vertically\n",
    "    else:\n",
    "        # Convert to float if not an object array or if it doesn't contain sparse matrices\n",
    "        feature_dense = feature_dense.astype(float)  \n",
    "    \n",
    "    labels = labels.astype(int)\n",
    "    accuracies = cross_val_score(model, feature_dense, labels, scoring='accuracy', cv=5)\n",
    "    for accuracy in accuracies:\n",
    "        cross_value_scored.append((model_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "549a5f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.997143</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.980010</td>\n",
       "      <td>0.009331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.880172</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Accuracy  Standard deviation\n",
       "model_name                                               \n",
       "LinearSVC                    0.997143            0.003912\n",
       "MultinomialNB                0.980010            0.009331\n",
       "RandomForestClassifier       0.880172            0.015470"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv = pd.DataFrame(cross_value_scored, columns =['model_name', 'accuracy'])\n",
    "acc = pd.concat([df_cv.groupby('model_name').accuracy.mean(),df_cv.groupby('model_name').accuracy.std()], axis= 1,ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb26e6c",
   "metadata": {},
   "source": [
    "# USARE GRIDSEARCH e cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58416a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [200, 500]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [200, 500]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8, 9, 10],\n",
       "                         'max_features': ['auto', 'log2'],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8,9,10],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "kfold5 = KFold(shuffle = True, n_splits = 5)\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= kfold5, verbose=1, n_jobs=-1)\n",
    "CV_rfc.fit(feature_dense, labels)\n",
    "\n",
    "\n",
    "# rfc_rs = RandomizedSearchCV(rfc, \n",
    "#                          param_distributions = param_grid,\n",
    "#                          cv = kfold_5,  \n",
    "#                          n_iter = 5, \n",
    "#                          scoring = 'roc_auc', \n",
    "#                          verbose = 3, \n",
    "#                          n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5111ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature to a dense NumPy array if it's sparse\n",
    "if sp.issparse(feature_test):\n",
    "    feature_test_dense = feature_test.toarray()\n",
    "else:\n",
    "    feature_test_dense = feature_test  # If not sparse, use feature directly\n",
    "\n",
    "# Check if feature_dense is an object array and contains sparse matrices\n",
    "if feature_test_dense.dtype == 'object' and any(sp.issparse(element) for element in feature_test_dense):\n",
    "    feature_test_dense = np.vstack([element.toarray() for element in feature_test_dense]) # stack the elements of arrays vertically\n",
    "else:\n",
    "    # Convert to float if not an object array or if it doesn't contain sparse matrices\n",
    "    feature_test_dense = feature_test_dense.astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c3414faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = CV_rfc.predict(feature_dense)\n",
    "pred_test = CV_rfc.predict(feature_test_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d0bc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test=pd.to_numeric(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5542f7",
   "metadata": {},
   "source": [
    "## risultati test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1ed218e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[99  1]\n",
      " [11 65]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(labels_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06b85e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Antimeridionalista       0.90      0.99      0.94       100\n",
      "            Neutro       0.98      0.86      0.92        76\n",
      "\n",
      "          accuracy                           0.93       176\n",
      "         macro avg       0.94      0.92      0.93       176\n",
      "      weighted avg       0.94      0.93      0.93       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels_test, pred_test, target_names=['Antimeridionalista', 'Neutro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371741fc",
   "metadata": {},
   "source": [
    "## risultati validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "924b3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_val=validation['tfidf']\n",
    "if sp.issparse(feature_val):\n",
    "    feature_val = feature_val.toarray()\n",
    "else:\n",
    "    feature_val = feature_val\n",
    "\n",
    "if feature_val.dtype == 'object' and any(sp.issparse(element) for element in feature_val):\n",
    "    feature_val = np.vstack([element.toarray() for element in feature_val])\n",
    "else:\n",
    "    feature_val = feature_val.astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6a9c1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val=pd.to_numeric(validation['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "acbc8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = CV_rfc.predict(feature_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "80550ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[300   0]\n",
      " [231   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fb85423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Antimeridionalista       0.56      1.00      0.72       300\n",
      "            Neutro       0.00      0.00      0.00       231\n",
      "\n",
      "          accuracy                           0.56       531\n",
      "         macro avg       0.28      0.50      0.36       531\n",
      "      weighted avg       0.32      0.56      0.41       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels_val, pred_val, target_names=['Antimeridionalista', 'Neutro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117ec1b",
   "metadata": {},
   "source": [
    "# Altri Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3e6ff63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(C=0.02, penalty='none')\n",
    "lr=lr.fit(feature_dense,labels)\n",
    "pred_val = lr.predict(feature_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "68903288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[256  44]\n",
      " [189  42]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1a50a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Antimeridionalista       0.58      0.85      0.69       300\n",
      "            Neutro       0.49      0.18      0.26       231\n",
      "\n",
      "          accuracy                           0.56       531\n",
      "         macro avg       0.53      0.52      0.48       531\n",
      "      weighted avg       0.54      0.56      0.50       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels_val, pred_val, target_names=['Antimeridionalista', 'Neutro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93eff76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a8e93f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC_Gaussian=SVC(C=0.2, kernel='poly', degree=15, class_weight='balanced', gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "42a88fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC_Gaussian.fit(feature_dense,labels)\n",
    "pred_val=svc.predict(feature_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "aa798e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[  0 300]\n",
      " [  0 231]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a5b476b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Antimeridionalista       0.00      0.00      0.00       300\n",
      "            Neutro       0.44      1.00      0.61       231\n",
      "\n",
      "          accuracy                           0.44       531\n",
      "         macro avg       0.22      0.50      0.30       531\n",
      "      weighted avg       0.19      0.44      0.26       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels_val, pred_val, target_names=['Antimeridionalista', 'Neutro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2bbde6",
   "metadata": {},
   "source": [
    "# COSTRUZIONE DATASET CON ALTRE FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831f914",
   "metadata": {},
   "source": [
    "#### aggiungiamo altre features ai dataset traintest e validation, che al momento hanno 'text', 'tfidf' e 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad231d",
   "metadata": {},
   "source": [
    "### nltk\n",
    "A questo punto abbiamo già fatto tokenization/lemmatization/stemming, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9da5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bae5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5c220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54c9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea47ceeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39adfd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519a144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454c779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae2d295",
   "metadata": {},
   "source": [
    "# CODICE VECCHIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c009632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4231fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4cd71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
